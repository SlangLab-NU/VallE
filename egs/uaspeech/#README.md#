Training JALL-E (Jordan's Vall-e)

1) Working directory

```
cd /home/data1/vall-e.git/VallE
```

2) Run venv

```
source .venv/bin/activate
```

3) Uaspeech directory

```
cd egs/uaspeech
```

4) Prep Data (IF NEEDED)

```
bash prepare.sh --stage -1 --stop-stage 3
```

5) create export directory

```
exp_dir=whatever_name_you_like
```

6) train AR decoder

```
python3 bin/trainer.py --max-duration 40 --filter-min-duration 0.5 --filter-max-duration 14 --train-stage 1       --num-buckets 6 --dtype "bfloat16" --save-every-n 1000 --valid-interval 500       --model-name valle --share-embedding true --norm-first true --add-prenet false       --decoder-dim 1024 --nhead 4 --num-decoder-layers 4 --prefix-mode 0       --base-lr 0.05 --warmup-steps 200 --average-period 0       --num-epochs 40 --start-epoch 1 --start-batch 0 --accumulate-grad-steps 8       --exp-dir ${exp_dir} 
```

7) copy best valid loss to epoch 2

```
cp ${exp_dir}/best-valid-loss.pt ${exp_dir}/epoch-2.pt  # --start-epoch 3=2+1
```

8) Train NAR Decoder

```
python3 bin/trainer.py --max-duration 40 --filter-min-duration 0.5 --filter-max-duration 14 --train-stage 2       --num-buckets 6 --dtype "float32" --save-every-n 1000 --valid-interval 500       --model-name valle --share-embedding true --norm-first true --add-prenet false       --decoder-dim 1024 --nhead 4 --num-decoder-layers 4 --prefix-mode 0       --base-lr 0.05 --warmup-steps 200 --average-period 0       --num-epochs 60 --start-epoch 1 --start-batch 0 --accumulate-grad-steps 8       --exp-dir ${exp_dir}
```

9) Run inference

```
python3 bin/infer.py --output-dir infer/demos     --checkpoint=${exp_dir}/best-valid-loss.pt     --atypical-audio /home/data1/vall-e.git/VallE/egs/uaspeech/audioSamples/CF02/CF02_B1_C1_M2.wav --text "COMMAND"
```

10) tensorboard
```
tensorboard --logdir=/home/data1/vall-e.git/VallE/egs/uaspeech/(exp_dir)/tensorboard_stage1 --host localhost --port 8088
```
